{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_cell": true
   },
   "source": [
    "<span class='note'>*Make me look good.* Click on the cell below and press <kbd>Ctrl</kbd>-<kbd>Enter</kbd>.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hide_cell": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open('css/custom.css', 'r').read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_cell": true
   },
   "source": [
    "<h5 class='prehead'>SA367 &middot; Mathematical Models for Decision Making &middot; Spring 2017 &middot; Uhan</h5>\n",
    "\n",
    "<h5 class='lesson'>Lesson 17.</h5>\n",
    "\n",
    "<h1 class='lesson_title'>Solving stochastic dynamic programs with Python</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's solve the stochastic dynamic program we formulated for the investment problem in Lesson 16.\n",
    "* In this class, we will use a package called `stochasticdp` to set up and solve stochastic dynamic programs.\n",
    "    - _Warning._ This is a package that I wrote. There may be some bugs.\n",
    "    - _Note._ This package is publicly available. Please feel free to use it in the future for other things. The source code is on [GitHub](https://github.com/nelsonuhan/stochasticdp)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing `stochasticdp`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To install `stochasticdp`, open a WinPython Command Prompt and type:\n",
    "\n",
    "```\n",
    "pip install stochasticdp\n",
    "```\n",
    "\n",
    "* To use `stochasticdp`, we must first import it. In `stochasticdp`, we only need the object `StochasticDP`, so we can perform our import like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from stochasticdp import StochasticDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a stochastic dynamic program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Recall the investment problem from Lesson 16:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Problem.__ Suppose you have \\$5,000 to invest, and at the beginning of each of the next 3 years, you have an opportunity to invest in either of two investments: A or B. Both investments have uncertain profits. For an investment of \\$5,000, the profits are as follows:\n",
    "\n",
    "| Investment | Profit (\\$) | Probability |\n",
    "|:-----------|------------:|------------:|\n",
    "| A          | -5,000      | 0.3         |\n",
    "|            | 5,000       | 0.7         |\n",
    "| B          | 0           | 0.9         |\n",
    "|            | 5,000       | 0.1         |\n",
    "                                     \n",
    "You are allowed to make at most one investment each year, and can invest only \\$5,000 each time. Any additional money accumulated is left idle.\n",
    "\n",
    "Formulate a stochastic dynamic program to find an investment policy that maximizes the probability you will have \\$10,000 after 3 years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's walk through setting up the stochastic DP we formulated in the last lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We had defined 4 stages - to make things easier, let's renumber the stages so they start at $t = 0$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{stage } t = 0, 1, 2 & \\quad\\leftrightarrow\\quad \\text{beginning of year $t$}\\\\\n",
    "t = 3 & \\quad\\leftrightarrow\\quad \\text{end of process}\n",
    "\\end{aligned}\n",
    "$$\n",
    "    \n",
    "* In each stage, we defined 3 states:\n",
    "\n",
    "$$\n",
    "\\text{state } n \\in \\{0, 5000, 10000\\} \\quad\\leftrightarrow\\quad \\text{$n$ dollars in account}\n",
    "$$\n",
    "\n",
    "* At each stage and state, we defined 3 possible decisions:\n",
    "\n",
    "$$\n",
    "\\text{decision } x_t \\in \\{ \\text{A}, \\text{B}, \\text{no investment} \\}\n",
    "$$\n",
    "\n",
    "* The set of _allowable_ decisions changed, depending on the stage and state. We'll address this later.\n",
    "\n",
    "* For now, we can initialize a stochastic dynamic program with these stages, states, and decisions like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of stages\n",
    "number_of_stages = 4\n",
    "\n",
    "# List of states\n",
    "states = [0, 5000, 10000]\n",
    "\n",
    "# List of decisions\n",
    "decisions = ['A', 'B', 'no investment']\n",
    "\n",
    "# Initialize stochastic dynamic program - we want to maximize, so minimize = False\n",
    "dp = StochasticDP(number_of_stages, states, decisions, minimize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The code above initializes a stochastic dynamic program called `dp`.\n",
    "\n",
    "* The transition probabilities, contributions, and boundary conditions in `dp` are all initialized to 0.\n",
    "\n",
    "* We need to change these appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition probabilities and contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First, let's tackle transitions from the state $n = 5000$:\n",
    "\n",
    "![n = 5000](img/5000.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the sketch we drew in Lesson 16, we left out the gray edges above, which represent transitions with probability 0. \n",
    "    - This seems unnecessary, but will become important to consider later.\n",
    "\n",
    "* Since the transition probabilities are already initialized to 0, we just need to focus on defining the blue edges.\n",
    "\n",
    "* The transition probability $p(m \\,|\\, n, t, x)$ of moving from state $n$ to state $m$ in stage $t$ under decision $x$ is represented by\n",
    "\n",
    "```python\n",
    "dp.transition[m, n, t, x]\n",
    "```\n",
    "\n",
    "* The contribution $c(m \\,|\\, n, t, x)$ of moving from state $n$ to state $m$ in stage $t$ under decision $x$ is represented by\n",
    "\n",
    "```python\n",
    "dp.contribution[m, n, t, x]\n",
    "```\n",
    "\n",
    "* So, we can input the transition probabilities and contributions from state $n = 5000$ in stages $t = 0, 1, 2$ as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transition probabilities and contributions from state n = 5000\n",
    "for t in range(number_of_stages - 1):\n",
    "    # Investment A\n",
    "    dp.transition[10000, 5000, t, 'A'] = 0.7\n",
    "    dp.contribution[10000, 5000, t, 'A'] = 0\n",
    "    \n",
    "    dp.transition[0, 5000, t, 'A'] = 0.3\n",
    "    dp.contribution[0, 5000, t, 'A'] = 0\n",
    "\n",
    "    # Investment B\n",
    "    dp.transition[10000, 5000, t, 'B'] = 0.1\n",
    "    dp.contribution[10000, 5000, t, 'B'] = 0\n",
    "    \n",
    "    dp.transition[5000, 5000, t, 'B'] = 0.9\n",
    "    dp.contribution[5000, 5000, t, 'B'] = 0\n",
    "\n",
    "    # No investment\n",
    "    dp.transition[5000, 5000, t, 'no investment'] = 1\n",
    "    dp.contribution[5000, 5000, t, 'no investment'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remember that the contributions for all transitions are 0 in this stochastic DP.\n",
    "\n",
    "* Since the contributions are all set to 0 in the initialization, we actually don't need to define the contributions, like we did above.\n",
    "\n",
    "* However, we'll continue to do so, for illustration purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Next, let's tackle the transitions from state $n = 0$. Last time, we sketched these transitions like this:\n",
    "\n",
    "![n = 0](img/0-1.png)\n",
    "\n",
    "* We can revise this sketch to explicitly include all the decisions, even the ones that are not allowable at state $n = 0$:\n",
    "\n",
    "![n = 0](img/0-2.png)\n",
    "\n",
    "* The gray edges above represent transitions with probability 0 and contribution 0.\n",
    "\n",
    "* Note that _all of the edges_ coming out of decisions A and B are grey. This represents the fact that A and B are _not allowable_ at this stage and state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Quick check._ What can the sum of the transition probabilities from any decision node equal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- _Write your notes here. Double-click to edit._ -->\n",
    "The transition probabilities from any decision node must add up to either 0 or 1. They will add up to 1 if the decision is allowable at that stage/state; otherwise they will add up to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So, we can input the transition probabilities and contributions from state $n = 0$ in stages $t = 0, 1, 2$ like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transition probabilities and contributions from state n = 0\n",
    "for t in range(number_of_stages - 1):\n",
    "    # Investment A - all transitions have probability 0, already done in initialization\n",
    "\n",
    "    # Investment B - all transitions have probability 0, already done in initialization\n",
    "\n",
    "    # No investment\n",
    "    dp.transition[0, 0, t, 'no investment'] = 1\n",
    "    dp.contribution[0, 0, t, 'no investment'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can tackle the transitions from state $n = 10000$ in an almost identical way:\n",
    "\n",
    "![n = 10000](img/10000-1.png)\n",
    "\n",
    "![n = 10000](img/10000-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transition probabilities and contributions from state n = 10000\n",
    "for t in range(number_of_stages - 1):\n",
    "    # Investment A - all transitions have probability 0, already done in initialization\n",
    "\n",
    "    # Investment B - all transitions have probability 0, already done in initialization\n",
    "\n",
    "    # No investment\n",
    "    dp.transition[10000, 10000, t, 'no investment'] = 1\n",
    "    dp.contribution[10000, 10000, t, 'no investment'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boundary conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Finally, we need to define the boundary conditions.\n",
    "\n",
    "* In particular, we need to specify the value-to-go function at the last stage (in our case, $t = 3$) for each state.\n",
    "\n",
    "* The boundary value for state $n$ is represented by:\n",
    "\n",
    "```python\n",
    "dp.boundary[n]\n",
    "```\n",
    "\n",
    "* So, we can input the boundary conditions like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Boundary conditions\n",
    "dp.boundary[0] = 0\n",
    "dp.boundary[5000] = 0\n",
    "dp.boundary[10000] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the stochastic dynamic program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Once the stochastic DP is setup, we can solve it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solve the stochastic dynamic program\n",
    "value, policy = dp.solve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note that the method `.solve()` outputs two objects: `value` and `policy`.\n",
    "\n",
    "* `value[t, n]` is the value-to-go function $f_t(n)$ at stage $t$ and state $n$.\n",
    "\n",
    "* `policy[t, n]` is the optimal decision $x_t^*$ that attains the value-to-go function $f_t(n)$ at stage $t$ and state $n$.\n",
    "\n",
    "* First, let's see what the value-to-go function looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Examine the value-to-go function\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Next, let's look at the corresponding policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Examine the policy\n",
    "policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On your own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Solve the stochastic DP we formulated in Lesson 15 for this problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Problem.__ The Hit-and-Miss Manufacturing Company has received an order to supply one item of a particular type. However, manufacturing this item is difficult, and the customer has specified such stringent quality requirements that the company may have to produce more than one item to obtain an item that is acceptable.\n",
    "                \n",
    "The company estimates that each item of this type will be acceptable with probability 1/2 and defective with probability 1/2. Each item costs \\$100 to produce, and excess items are worthless. In addition, a setup cost of \\$300 must be incurred whenever the production process is setup for this item. The company has time to make no more than 3 production runs, and at most 5 items can be produced in each run. If an acceptable item has not been obtained by the end of the third production run, the manufacturer is in breach of contract and must pay a penalty of \\$1600.\n",
    "                \n",
    "The objective is to determine how many items to produce in each production run in order to minimize the total expected cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of stages\n",
    "number_of_stages = 4\n",
    "\n",
    "# List of states\n",
    "states = [0, 1]\n",
    "\n",
    "# List of decisions\n",
    "decisions = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "# Initialize stochastic dynamic program\n",
    "dp = StochasticDP(number_of_stages, states, decisions, minimize=True)\n",
    "\n",
    "# Transition probabilities and contributions from state n = 0\n",
    "for t in range(number_of_stages - 1):\n",
    "    for x in decisions:\n",
    "        dp.transition[1, 0, t, x] = 0\n",
    "        dp.contribution[1, 0, t, x] = 0\n",
    "        \n",
    "        dp.transition[0, 0, t, x] = 1\n",
    "        dp.contribution[0, 0, t, x] = 0 \n",
    "\n",
    "# Transition probabilities and contributions from state n = 1\n",
    "for t in range(number_of_stages - 1):\n",
    "    for x in decisions:\n",
    "        if x > 0:\n",
    "            K = 3\n",
    "        else:\n",
    "            K = 0\n",
    "            \n",
    "        dp.transition[0, 1, t, x] = 1 - (1/2)**x\n",
    "        dp.contribution[0, 1, t, x] = K + x\n",
    "        \n",
    "        dp.transition[1, 1, t, x] = (1/2)**x\n",
    "        dp.contribution[1, 1, t, x] = K + x\n",
    "        \n",
    "# Boundary conditions\n",
    "dp.boundary[0] = 0\n",
    "dp.boundary[1] = 16\n",
    "\n",
    "# Solve the stochastic dynamic program\n",
    "value, policy = dp.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Examine value-to-go\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Examine policy\n",
    "policy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_metadata": {
   "lesson": "17",
   "lessontitle": "Solving stochastic dynamic programs with Python",
   "shortlessontitle": "Solving stochastic dynamic programs with Python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
